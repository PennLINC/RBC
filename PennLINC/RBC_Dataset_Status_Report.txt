RBC Dataset Status Report (DSR)

CCNP (GONG)
TODO: DECIDE FIELDMAPLESS OR NO (MATT AND AZEEZ)
RIA Store: ssh://sciget.pmacs.upenn.edu/project/RBC/RIA/BIDS/970/4eab1-3320-41f0-9fce-3c6961b4ac96
Cubic Path: /cbica/projects/RBC/RBC_RAWDATA/bidsdatasets
Final CuBIDS Outputs: https://github.com/PennLINC/RBC/tree/master/PennLINC/CCNP_BIDS_Fix
Datalad Status: saved, clean
Git Branch: master
DSR: All CCNP subjects ran through fmriprep successfully. We also ran XCP on the entire CCNP, which finished yesterday. Audit finished running on CCNP XCP, revealed 9 subjects failed on brain_plot/reho, and did not generate output branches. Matt then created a fieldmapless fmriprpep bootstrap script, and ran that on CCNP. We then ran the audit on the fieldmapless CCNP fmriprep outputs, which came out clean. 
Next Steps: Run XCP on fieldmapless. Add README + Authors.

HRC (GONG)
TODO: DECIDE FIELDMAPLESS OR NO (MATT AND AZEEZ)
RIA Store: ssh://sciget.pmacs.upenn.edu/project/RBC/RIA/BIDS/98f/55d34-d001-40ac-8056-db2803d3280f
Cubic Path: /cbica/projects/RBC/RBC_RAWDATA/bidsdatasets/HRC
Datalad Status: unlocked
Git Branch: main
DSR: We ran the exemplars through fmriprep using the fieldmapless AND multisession fmriprep.
Next Steps: Audit the fieldmapless/multi-session fmriprep outputs. Run the entire dataset through fieldmapless/multi-session fmriprep. Then move onto XCP.
Data Narrative: https://github.com/PennLINC/HRC/blob/main/working/curation_code/DataNarrative.md

PNC (GONG)
TODO: DECIDE IF WE WANT TO USE NEW OR OLD XCP (AZEEZ AND MAX, CHECK CORRELATION BETWEEN OLD AND NEW ON CCNP BEFORE USING NEW ON PNC)
RIA Store: ssh://sciget.pmacs.upenn.edu/project/RBC/RIA/BIDS/6a5/7d847-1441-442d-81d7-04ca51526645
Cubic Path: /cbica/projects/RBC/RBC_RAWDATA/bidsdatasets/PNC
Datalad Status: saved, clean
Git Branch: master
DSR: Fmriprep finished running on the entire dataset. Ran the new bootstrap version of the audit on the fmriprep outputs. 
Next Steps: Concatenate single subject audit outputs and check results. Run qsiprep on exemplars and XCP on the entire dataset. 
Data Narrative: /cbica/projects/RBC/PNC/working/curation_code/DataNarrative.md

HBN
RIA Store: ssh://sciget.pmacs.upenn.edu/project/RBC/RIA/BIDS/b32/508c1-d2c1-4b40-a3e3-48df49e7fa56
Cubic Path: /cbica/projects/RBC/RBC_RAWDATA/bidsdatasets/HBN
Datalad Status: saved, clean
Git Branch: master
DSR: After doing a little digging through the aws indi bucket, we realized that out of the 55 cbic subjects scanned with abcd protocol, we are currently missing 32 from cubic. These subjects are not in the /BIDS_CURATED folder but are in the /MRI/SITE-CBIC folder. After checking with Alex, we recieved the ok to upload those 32 to cubic. We also identified four participants on Cubic who do not exist anywhere on aws––they are in neither /BIDS_CURATED nor any of the /MRI/SITE-* folders. Alex gave us the ok to delete those four subjects, as they each have only one scan. Downloaded 32 subjects scanned with abcd protocol from aws to dopamine. Added the cbic session to make bids valid and ran add-nifti-info. We then ran group/validate. Group came out clean. Validate revealed that the 32 newly uploaded scans are not at all bids valid. Spoke with Alex, and he asked us to validate them. For the 32 with bids errors, we added a session directory and added the session name to the filepaths. Group/validate running now. 
Next Steps: Need to deal with weird aquisitions (e.g. acq-MRoff and acq-MRon, no MR key group name!) DELETE EXTRANEOUS T1ws and T2ws (and PD???). RUN TOO SHORT BOLD/DWI CHECK AND PURGE IF NECESSARY!Delete four site-RU subs with half a functional scan, at Alex's suggestion. Rename 55 subs with crazy protocol to include acq-abcd_protocol in filenamesSave. Add events tsvs (have peer, need movieDM and movieTP). Use tolerances listed below, apply changes, and push back to PMACS. 
Data Narrative: https://github.com/PennLINC/RBC/blob/master/PennLINC/HBN_BIDS_Fix/HBN_Data_Narrative.md

NKI
Datalad Status: untracked changes: purged too short bold scans, exchanged incorrect T2w jsons for correct ones (including 8 we coppied from sub-A00031794_ses-FLU1_T2w.json because we noticed Alex only gave us 117/125 of the correct jsons. Added nifti info.
Git Branch: main
Cubic Path: /cbica/projects/RBC/RBC_RAWDATA/bidsdatasets/NKI
DSR: Purged list of too short bold scans (compiled according to the rules we established with Alex). Validate revealed there are now 3 subjects for whom a too short bold scan was their only scan, so those three empty subject directores were deleted. The subjectIDs for those three subjects are the following: sub-A00075231, sub-A00037375, and sub-A00081079. Alex regenerated the correct jsons for the 117/125 T2w scans that were incorrect and gave us the go ahead to copy existing T2w sidecars to create the remaining 8 jsons that needed to be replaced, since the T2ws all used the same protocol. We replaced the incorrect sidecars with the new ones and ran add-nifti-info. Group/validate ran overnight. Copied sub-A00031794_ses-FLU1_T2w.json to replace the 8 T2w scans with missing sidecars still and ran add nifti info. Group/validate running came out clean! Save running now!
Next Steps: Truncate subject level events tsvs. Group using config tolerances from meeting with Alex, and apply changes. 


NKI TOLERANCES (from meeting with Alex)
DWI: tolerate 2.4-2.8 TR, tolerate all echo time

HBN FINAL TOLERNACES 
ANAT: EchoTime: 0.002, 
DWI: group 1 = CBIC/CUNY, group 2 = RU, group 3 = SI, EES, TRT, TR 
FMAP: VoxelSizeDim*:0.05mm, EES:0.0001, TRT: 0.01 
FUNC: EES:precision=4, TRT:precision=2

HBN ISSUES (OLD)
- ANAT: Change T1 key group with no acq value to acquisition-SI
- ANAT: Need to delete some T2s, waiting on CMI for which ones (Mike or Alex)
- ANAT: RULE FOR T1s: Ideally, keep the VnavNorm scan with the highest rating. If unscored, keep best one (from plot), if can't tell difference, keep first run. If no VnavNorm, keep Vnav. If neither, keep HCP. 
- DWI + FMAP: tolerate Effective Echo Spacing, Total Readout Time, and Repetition Time
- FMAP: lots of missing PRFIP and MAF, want this in filename? want separate group because of this? SHORTHAND FOR ACQUISITION (UNSET SUGGEST VARIANT RENAME)! 
- FMAP: tolerate VoxelSizeDim1 (0.05mm)
- ADD PixelBandwith to sidecar params!!!!
- RERUN GROUP WITH SES INCLUDED IN GROUPINGS! 

NKI BOLD (DELETED)
(1) task-checkerboard scans with less than the dominant group's quantity of data
- 19 acq-645 check scans with less than the dominant group's quantity of data: 240*0.645/60 = 2.58 mins of data
- 8 check acq-1400 check scans with less than the dominant group's quantity of data: 98*1.4/60 = 2.28666666667 mins of data
- 2 acq-1400RR scans with less than the dominant group's quantity of data: 98*1.4/60 = 2.28666666667 mins of data
- 2 check acq-65RR scans with less than the dominant group's quantity of data: 240*0.645/60 = 2.58 mins of data

(2) 60 task-rest scans with less than 3 mins of data 

(3) task-breathhold 
- 3 breath acq-1400RR scans with less than the dominant group's quantity of data: 191*1.4/60 = 4.45666666667 mins of data
- 20 acq-1400 breathhold scans that have less than the dominant group's quantity of data: 186*1.4/60 = 4.34 mins of data
The task-breathhold dominant groups have more than 3 mins of data. 


HRC ISSUES
- VALIDATION: 11 new subs still quick validation failing ('bids dir structure doesn't match' description so maybe just having an issue with ses-3?) using the --sequential flag! Matt and I found nothing wrong with them (likely just need to debug the new flag. They passed validation WITHOUT the sequential flag. 
