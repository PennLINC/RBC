{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Outputs\n",
    "\n",
    "This notebook merges the outputs of the BIDS validator run on individual subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_validator(path):\n",
    "\n",
    "    def get_nested(dct, *keys):\n",
    "        for key in keys:\n",
    "            try:\n",
    "                dct = dct[key]\n",
    "            except (KeyError, TypeError):\n",
    "                return None\n",
    "        return dct\n",
    "\n",
    "    with open(path, 'r') as read_file:\n",
    "        data = json.load(read_file)\n",
    "\n",
    "    issues = data['issues']\n",
    "\n",
    "    def parse_issue(issue_dict):\n",
    "\n",
    "        return_dict = {}\n",
    "        return_dict['files'] = [get_nested(x, 'file', 'relativePath') for x in issue_dict.get('files', '')]\n",
    "        return_dict['type'] = issue_dict.get('key' '')\n",
    "        return_dict['severity'] = issue_dict.get('severity', '')\n",
    "        return_dict['description'] = issue_dict.get('reason', '')\n",
    "        return_dict['code'] = issue_dict.get('code', '')\n",
    "        return_dict['url'] = issue_dict.get('helpUrl', '')\n",
    "\n",
    "        return(return_dict)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for warn in issues['warnings']:\n",
    "\n",
    "        parsed = parse_issue(warn)\n",
    "        parsed = pd.DataFrame(parsed)\n",
    "        df = df.append(parsed, ignore_index=True)\n",
    "\n",
    "    for err in issues['errors']:\n",
    "\n",
    "        parsed = parse_issue(err)\n",
    "        parsed = pd.DataFrame(parsed)\n",
    "        df = df.append(parsed, ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "issues = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/cbica/projects/RBC/flywheel_curation/RBC/PennLINC/Validation/CUBIC_Curation/pnc_issues.json']\n",
      "Last Run: 2020-10-13 01:22:26.441702\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severity</th>\n",
       "      <th>type</th>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">error</th>\n",
       "      <th>DWI_MISSING_BVAL</th>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DWI_MISSING_BVEC</th>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECHO_TIME1-2_NOT_DEFINED</th>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOT_INCLUDED</th>\n",
       "      <th>1</th>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">warning</th>\n",
       "      <th>EVENTS_TSV_MISSING</th>\n",
       "      <th>25</th>\n",
       "      <td>3067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INCONSISTENT_PARAMETERS</th>\n",
       "      <th>39</th>\n",
       "      <td>1597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISSING_MAGNITUDE1_FILE</th>\n",
       "      <th>92</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO_AUTHORS</th>\n",
       "      <th>113</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>README_FILE_MISSING</th>\n",
       "      <th>101</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       files\n",
       "                                       count\n",
       "severity type                     code      \n",
       "error    DWI_MISSING_BVAL         33       1\n",
       "         DWI_MISSING_BVEC         32       1\n",
       "         ECHO_TIME1-2_NOT_DEFINED 15      17\n",
       "         NOT_INCLUDED             1     5650\n",
       "warning  EVENTS_TSV_MISSING       25    3067\n",
       "         INCONSISTENT_PARAMETERS  39    1597\n",
       "         MISSING_MAGNITUDE1_FILE  92      17\n",
       "         NO_AUTHORS               113      0\n",
       "         README_FILE_MISSING      101      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'PNC'\n",
    "path = '/cbica/projects/RBC/flywheel_curation/RBC/PennLINC/Validation/CUBIC_Curation/{}_issues.json'.format(dataset.lower())\n",
    "all_files = glob.glob(path)\n",
    "print(all_files)\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = parse_validator(filename)\n",
    "    df['subject'] = filename.split('/')[7]\n",
    "    li.append(df)\n",
    "    \n",
    "issues[dataset] = pd.concat(li, axis=0, ignore_index=True)\n",
    "print('Last Run:', datetime.datetime.now())\n",
    "issues[dataset][['severity', 'type', 'files', 'code']].groupby(['severity', 'type', 'code']).agg(['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing BVAL & BVEC in code 32 and 33 are a confirmed subject who has none of these files in their DICOM. Additionally, 17 subjects have only a phasediff file and no magnitude fieldmaps, for code 15. Lastly, NOT_INCLUDED errors refer to the ASL files which are not in the BIDS spec. PNC is complete on CUBIC!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues[dataset].to_csv('/cbica/projects/RBC/flywheel_curation/RBC/PennLINC/Validation/CUBIC_Curation/{}_validation.csv'.format(dataset), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/cbica/projects/RBC/flywheel_curation/RBC/PennLINC/Validation/CUBIC_Curation/hbn_issues.json']\n",
      "Last Run: 2020-10-13 01:22:26.963124\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severity</th>\n",
       "      <th>type</th>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">warning</th>\n",
       "      <th>EVENTS_TSV_MISSING</th>\n",
       "      <th>25</th>\n",
       "      <td>8627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INCONSISTENT_PARAMETERS</th>\n",
       "      <th>39</th>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO_AUTHORS</th>\n",
       "      <th>113</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>README_FILE_MISSING</th>\n",
       "      <th>101</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      files\n",
       "                                      count\n",
       "severity type                    code      \n",
       "warning  EVENTS_TSV_MISSING      25    8627\n",
       "         INCONSISTENT_PARAMETERS 39     621\n",
       "         NO_AUTHORS              113      0\n",
       "         README_FILE_MISSING     101      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'HBN'\n",
    "path = '/cbica/projects/RBC/flywheel_curation/RBC/PennLINC/Validation/CUBIC_Curation/{}_issues.json'.format(dataset.lower())\n",
    "all_files = glob.glob(path)\n",
    "print(all_files)\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = parse_validator(filename)\n",
    "    df['subject'] = filename.split('/')[7]\n",
    "    li.append(df)\n",
    "    \n",
    "issues[dataset] = pd.concat(li, axis=0, ignore_index=True)\n",
    "print('Last Run:', datetime.datetime.now())\n",
    "issues[dataset][['severity', 'type', 'files', 'code']].groupby(['severity', 'type', 'code']).agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues[dataset].to_csv('/cbica/projects/RBC/flywheel_curation/RBC/PennLINC/Validation/CUBIC_Curation/{}_validation.csv'.format(dataset), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NKI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/cbica/projects/RBC/flywheel_curation/RBC/PennLINC/Validation/CUBIC_Curation/nki_issues.json']\n",
      "Last Run: 2020-10-13 01:22:27.419300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severity</th>\n",
       "      <th>type</th>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">error</th>\n",
       "      <th>EMPTY_FILE</th>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOT_INCLUDED</th>\n",
       "      <th>1</th>\n",
       "      <td>7135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SESSION_VALUE_CONTAINS_ILLEGAL_CHARACTER</th>\n",
       "      <th>63</th>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       files\n",
       "                                                       count\n",
       "severity type                                     code      \n",
       "error    EMPTY_FILE                               99       1\n",
       "         NOT_INCLUDED                             1     7135\n",
       "         SESSION_VALUE_CONTAINS_ILLEGAL_CHARACTER 63     102"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'NKI'\n",
    "path = '/cbica/projects/RBC/flywheel_curation/RBC/PennLINC/Validation/CUBIC_Curation/{}_issues.json'.format(dataset.lower())\n",
    "all_files = glob.glob(path)\n",
    "print(all_files)\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = parse_validator(filename)\n",
    "    df['subject'] = filename.split('/')[7]\n",
    "    li.append(df)\n",
    "    \n",
    "issues[dataset] = pd.concat(li, axis=0, ignore_index=True)\n",
    "print('Last Run:', datetime.datetime.now())\n",
    "issues[dataset][['severity', 'type', 'files', 'code']].groupby(['severity', 'type', 'code']).agg(['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For code 1 (`NOT_INCLUDED`), it's confirmed that all 204 items are compressed tsv files, ending in `physio.tsv.gz`, hence they are not included in the BIDS spec.\n",
    "\n",
    "These same errors are included in code 64 (`SESSION_VALUE_CONTAINS_ILLEGAL_CHARACTER`) and all account for instances of physio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues[dataset].to_csv('/cbica/projects/RBC/flywheel_curation/RBC/PennLINC/Validation/CUBIC_Curation/{}_validation.csv'.format(dataset), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
